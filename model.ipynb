{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DEVICE\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DATA TRANSFORMS\n",
    "# -----------------------------\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DATA LOADERS\n",
    "# -----------------------------\n",
    "DATA_DIR = \"/content/data\"\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_tfms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "class_names = train_ds.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 1: OA vs NO OA\n",
    "# -----------------------------\n",
    "binary_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "# Fine-tune last two layers\n",
    "for p in binary_model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in list(binary_model.layer3.parameters()) + list(binary_model.layer4.parameters()):\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n",
    "binary_model.fc = nn.Linear(binary_model.fc.in_features, 2)\n",
    "binary_model = binary_model.to(device)\n",
    "\n",
    "\n",
    "binary_loss = nn.CrossEntropyLoss()\n",
    "binary_opt = optim.Adam(filter(lambda p: p.requires_grad, binary_model.parameters()), lr=1e-4)\n",
    "binary_scheduler = ReduceLROnPlateau(binary_opt, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# STAGE 2: SEVERITY (KL 1-4)\n",
    "# -----------------------------\n",
    "severity_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "for p in severity_model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in list(severity_model.layer3.parameters()) + list(severity_model.layer4.parameters()):\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n",
    "severity_model.fc = nn.Linear(severity_model.fc.in_features, 4)\n",
    "severity_model = severity_model.to(device)\n",
    "\n",
    "\n",
    "severity_loss = nn.CrossEntropyLoss()\n",
    "severity_opt = optim.Adam(filter(lambda p: p.requires_grad, severity_model.parameters()), lr=1e-4)\n",
    "severity_scheduler = ReduceLROnPlateau(severity_opt, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TRAINING FUNCTION\n",
    "# -----------------------------\n",
    "def train_model(model, loader, criterion, optimizer, scheduler=None, epochs=75, is_binary=True):\n",
    "    all_acc = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct, total, running_loss = 0, 0, 0\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            if is_binary:\n",
    "                labels = (labels > 0).long().to(device)\n",
    "            else:\n",
    "                mask = labels > 0\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "                imgs = imgs[mask].to(device)\n",
    "                labels = (labels[mask] - 1).to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += len(labels)\n",
    "            running_loss += loss.item() * len(labels)\n",
    "\n",
    "\n",
    "        epoch_acc = correct / total\n",
    "        epoch_loss = running_loss / total\n",
    "        all_acc.append(epoch_acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "\n",
    "        # Scheduler step (ReduceLROnPlateau expects a metric)\n",
    "        if scheduler:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "\n",
    "    return all_acc\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN BOTH MODELS\n",
    "# -----------------------------\n",
    "print(\"=== Training Binary Model (OA vs NO OA) ===\")\n",
    "bin_train_acc = train_model(binary_model, train_loader, binary_loss, binary_opt, binary_scheduler, epochs=75, is_binary=True)\n",
    "\n",
    "\n",
    "print(\"\\n=== Training Severity Model (KL 1-4) ===\")\n",
    "sev_train_acc = train_model(severity_model, train_loader, severity_loss, severity_opt, severity_scheduler, epochs=75, is_binary=False)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATION\n",
    "# -----------------------------\n",
    "binary_model.eval()\n",
    "severity_model.eval()\n",
    "\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        bin_out = binary_model(imgs)\n",
    "        bin_pred = bin_out.argmax(1)\n",
    "\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if bin_pred[i] == 0:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                sev_out = severity_model(imgs[i:i+1])\n",
    "                sev_pred = sev_out.argmax(1).item() + 1\n",
    "                y_pred.append(sev_pred)\n",
    "\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Final Validation Accuracy:\", acc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix â€“ Two-Stage OA Model\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar()\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
